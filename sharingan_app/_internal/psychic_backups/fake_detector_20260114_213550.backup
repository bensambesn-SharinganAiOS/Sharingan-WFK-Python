{
  "capability_name": "fake_detector",
  "content": "#!/usr/bin/env python3\n\"\"\"\nSharingan OS - Fake Detector & Readiness Validator\nDetects fake outputs, placeholders, and validates system readiness.\nAuteur: Ben Sambe\n\"\"\"\n\nimport re\nimport sys\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n# Patterns de d\u00e9tection de fakes\nFAKE_PATTERNS = {\n    \"placeholder\": [\n        r\"AI Response to:\",\n        r\"AI Error:\",\n        r\"\\[PLACEHOLDER\\]\",\n        r\"\\[TODO\\]\",\n        r\"\\[FIXME\\]\",\n        r\"\\<TBD\\>\",\n        r\"\\<TODO\\>\",\n        r\"Not implemented yet\",\n        r\"To be implemented\",\n        r\"Coming soon\",\n    ],\n    \"vague_response\": [\n        r\"I can't help with that\",\n        r\"I'm not able to\",\n        r\"As an AI language model\",\n        r\"I apologize, but I cannot\",\n        r\"I'm sorry, but I can't\",\n    ],\n    \"incomplete\": [\n        r\"\\.\\.\\.\",\n        r\"\\[?\\]\",\n        r\"etc\\.?\",\n        r\"and so on\",\n    ],\n    \"shell_fake\": [\n        r\"Command not found\",\n        r\"command not found\",\n        r\"No such file or directory\",\n        r\"permission denied\",\n        r\"command failed\",\n    ]\n}\n\n\n@dataclass\nclass FakeResult:\n    \"\"\"R\u00e9sultat de d\u00e9tection de fake\"\"\"\n    is_fake: bool\n    fake_type: Optional[str]\n    confidence: float\n    details: str\n    suggestions: List[str]\n\n\nclass FakeDetector:\n    \"\"\"\n    D\u00e9tecte les outputs fake, placeholders et r\u00e9ponses incompl\u00e8tes.\n    Garantit que le syst\u00e8me ne renvoie pas de fausses donn\u00e9es.\n    \"\"\"\n    \n    def __init__(self):\n        self.detection_history: List[Dict] = []\n        \n    def detect_fakes(self, content: str, context: str = \"general\") -> FakeResult:\n        \"\"\"\n        D\u00e9tecte si le contenu est un fake/placeholder.\n        \n        Args:\n            content: Contenu \u00e0 analyser\n            context: Contexte (ai_response, shell_output, code, etc.)\n        \n        Returns:\n            FakeResult avec d\u00e9tection\n        \"\"\"\n        if not content or len(content.strip()) == 0:\n            return FakeResult(\n                is_fake=True,\n                fake_type=\"empty\",\n                confidence=1.0,\n                details=\"Content is empty\",\n                suggestions=[\"Provide actual content\"]\n            )\n        \n        # V\u00e9rifier chaque cat\u00e9gorie de fake\n        for category, patterns in FAKE_PATTERNS.items():\n            for pattern in patterns:\n                if re.search(pattern, content, re.IGNORECASE):\n                    return FakeResult(\n                        is_fake=True,\n                        fake_type=category,\n                        confidence=0.9,\n                        details=f\"Detected fake pattern: {pattern}\",\n                        suggestions=[\n                            f\"Remove or replace {pattern}\",\n                            \"Provide actual data instead of placeholder\"\n                        ]\n                    )\n        \n        # V\u00e9rifier les r\u00e9ponses trop vagues\n        if self._is_vague_response(content):\n            return FakeResult(\n                is_fake=True,\n                fake_type=\"vague\",\n                confidence=0.7,\n                details=\"Response is too vague or non-committal\",\n                suggestions=[\"Provide specific, actionable information\"]\n            )\n        \n        # D\u00e9tection de shell fake\n        if context == \"shell_output\":\n            if self._is_shell_fake(content):\n                return FakeResult(\n                    is_fake=True,\n                    fake_type=\"shell_error\",\n                    confidence=0.8,\n                    details=\"Shell output indicates failure\",\n                    suggestions=[\"Fix the underlying command or script\"]\n                )\n        \n        return FakeResult(\n            is_fake=False,\n            fake_type=None,\n            confidence=1.0,\n            details=\"Content appears genuine\",\n            suggestions=[]\n        )\n    \n    def _is_vague_response(self, content: str) -> bool:\n        \"\"\"V\u00e9rifie si la r\u00e9ponse est trop vague\"\"\"\n        vague_indicators = [\n            content.lower().startswith(\"it depends\"),\n            content.lower().startswith(\"maybe\"),\n            content.lower().startswith(\"possibly\"),\n            \"could be\" in content.lower() and len(content) < 50,\n        ]\n        return any(vague_indicators)\n    \n    def _is_shell_fake(self, content: str) -> bool:\n        \"\"\"V\u00e9rifie si l'output shell est un fake/erreur\"\"\"\n        error_indicators = [\n            \"command not found\" in content.lower(),\n            \"no such file\" in content.lower(),\n            \"failed\" in content.lower() and \"error\" in content.lower(),\n            \"permission denied\" in content.lower(),\n        ]\n        return any(error_indicators)\n    \n    def validate_ai_response(self, response: str, query: str) -> Tuple[bool, str]:\n        \"\"\"\n        Valide qu'une r\u00e9ponse IA est authentique.\n        \n        Returns:\n            (is_valid, message)\n        \"\"\"\n        result = self.detect_fakes(response, context=\"ai_response\")\n        \n        if result.is_fake:\n            return False, f\"Fake detected: {result.details}\"\n        \n        # V\u00e9rifier pertinence\n        if self._is_unrelated(response, query):\n            return False, \"Response appears unrelated to query\"\n        \n        return True, \"Response is valid\"\n    \n    def _is_unrelated(self, response: str, query: str) -> bool:\n        \"\"\"V\u00e9rifie si la r\u00e9ponse est sans rapport avec la query\"\"\"\n        # Extraire mots-cl\u00e9s de la query\n        query_words = set(re.findall(r'\\b\\w+\\b', query.lower()))\n        response_words = set(re.findall(r'\\b\\w+\\b', response.lower()))\n        \n        # Si moins de 20% de mots en commun et query longue\n        if len(query_words) > 5:\n            overlap = len(query_words & response_words)\n            if overlap / len(query_words) < 0.2:\n                return True\n        return False\n    \n    def validate_readiness(self) -> Dict:\n        \"\"\"\n        Valide que le syst\u00e8me Sharingan est pr\u00eat \u00e0 fonctionner.\n        \n        Returns:\n            Dict avec status de chaque composant\n        \"\"\"\n        results = {\n            \"ready\": True,\n            \"components\": {},\n            \"issues\": [],\n            \"timestamp\": str(__import__(\"datetime\").datetime.now())\n        }\n        \n        # V\u00e9rifier Python\n        results[\"components\"][\"python\"] = {\n            \"status\": \"ok\" if sys.version_info >= (3, 10) else \"old\",\n            \"version\": sys.version\n        }\n        \n        # V\u00e9rifier modules essentiels\n        essential_modules = [\n            (\"sharingan_os\", \"Core OS\"),\n            (\"ai_providers\", \"AI Providers\"),\n            (\"system_consciousness\", \"Consciousness\"),\n            (\"context_manager\", \"Context\"),\n            (\"genome_memory\", \"Genome Memory\"),\n        ]\n        \n        for module_name, description in essential_modules:\n            try:\n                __import__(module_name)\n                results[\"components\"][module_name] = {\n                    \"status\": \"ok\",\n                    \"description\": description\n                }\n            except ImportError as e:\n                results[\"components\"][module_name] = {\n                    \"status\": \"missing\",\n                    \"description\": description,\n                    \"error\": str(e)\n                }\n                results[\"ready\"] = False\n                results[\"issues\"].append(f\"Missing module: {module_name}\")\n        \n        return results\n\n\ndef detect_fakes(content: str, context: str = \"general\") -> FakeResult:\n    \"\"\"Fonction helper pour d\u00e9tection rapide de fakes\"\"\"\n    detector = FakeDetector()\n    return detector.detect_fakes(content, context)\n\n\ndef validate_readiness() -> Dict:\n    \"\"\"Fonction helper pour valider la pr\u00e9paration du syst\u00e8me\"\"\"\n    detector = FakeDetector()\n    return detector.validate_readiness()\n\n\n# Alias pour imports\n__all__ = [\"FakeDetector\", \"detect_fakes\", \"validate_readiness\", \"FakeResult\"]\n",
  "checksum": "8ebba8f510f88acddfa0d4757ca782312f5f2fa9a48616b36631fa77fa5bd4fa",
  "created_at": "2026-01-14T21:35:50.182450",
  "version": "1.0"
}